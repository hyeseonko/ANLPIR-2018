{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SIAMESE NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import and required packages\n",
    "\n",
    "For this lesson you will need some popular packages such as numpy and pandas in addition to PyTorch and torchtext. The latter can be installed via:\n",
    "\n",
    "`> pip install torchtext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch imports.\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Required for displaying plots from pandas dataframes.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Required for displaying images in the notebook.\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "# Setting seeds for reproducibility.\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dim = 300\n",
    "hidden_size = 100\n",
    "gpu = 0\n",
    "learning_rate = 0.001\n",
    "max_sent_len = 50\n",
    "print_freq = 1000\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The PyTorch and torchtext dataset API\n",
    "\n",
    "We will process the datasets using a standard dataset API which will provide us with an uniform input format for our data. It is recommended to directly look at the code and docstrings for understanding the dataset API: [https://github.com/pytorch/text/tree/master/torchtext/data](https://github.com/pytorch/text/tree/master/torchtext/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Quora():\n",
    "    def __init__(self, batch_size, embedding_dim, gpu):\n",
    "        self.RAW = data.RawField()\n",
    "        self.TEXT = data.Field(batch_first=True,\n",
    "                               lower=True,\n",
    "                               fix_length=max_sent_len)\n",
    "        self.LABEL = data.Field(sequential=False,\n",
    "                                unk_token=None)\n",
    "\n",
    "        self.train, self.dev, self.test = data.TabularDataset.splits(\n",
    "            path='./quora',\n",
    "            train='train.tsv',\n",
    "            validation='dev.tsv',\n",
    "            test='test.tsv',\n",
    "            format='tsv',\n",
    "            fields=[('label', self.LABEL),\n",
    "                    ('q1', self.TEXT),\n",
    "                    ('q2', self.TEXT),\n",
    "                    ('id', self.RAW)])\n",
    "\n",
    "        self.TEXT.build_vocab(self.train, self.dev, self.test, \n",
    "                              vectors=GloVe(name='6B', dim=embedding_dim),\n",
    "                              unk_init=torch.zeros((1, embedding_dim)).uniform_(-0.25, 0.25))\n",
    "        \n",
    "        self.LABEL.build_vocab(self.train)\n",
    "\n",
    "        self.train_iter, self.dev_iter, self.test_iter = \\\n",
    "            data.Iterator.splits((self.train, self.dev, self.test),\n",
    "                                 device=gpu,\n",
    "                                 batch_sizes=[batch_size] * 3,\n",
    "                                 shuffle=True)\n",
    "\n",
    "        self.max_word_len = max([len(w) for w in self.TEXT.vocab.itos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Instantiating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './quora/train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2b6e7af247aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munk_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpad_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b3782e3040a6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, embedding_dim, gpu)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     ('id', self.RAW)])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         self.TEXT.build_vocab(self.train, self.dev, self.test, \n",
      "\u001b[0;32m/home/noname/environments/main/local/lib/python2.7/site-packages/torchtext/data/dataset.pyc\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         train_data = None if train is None else cls(\n\u001b[0;32m---> 76\u001b[0;31m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[1;32m     77\u001b[0m         val_data = None if validation is None else cls(\n\u001b[1;32m     78\u001b[0m             os.path.join(path, validation), **kwargs)\n",
      "\u001b[0;32m/home/noname/environments/main/local/lib/python2.7/site-packages/torchtext/data/dataset.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, format, fields, skip_header, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m             'tsv': Example.fromCSV, 'csv': Example.fromCSV}[format.lower()]\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municode_csv_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './quora/train.tsv'"
     ]
    }
   ],
   "source": [
    "dataset = Quora(batch_size, embedding_dim, gpu)\n",
    "word_vocab_size = len(dataset.TEXT.vocab)\n",
    "unk_id = dataset.TEXT.vocab.stoi['<unk>']\n",
    "pad_id = dataset.TEXT.vocab.stoi['<pad>']\n",
    "\n",
    "print('[INFO] Vocabulary size: {}'.format(word_vocab_size))\n",
    "print('[INFO] <unk> id: {}'.format(unk_id))\n",
    "print('[INFO] <pad> id: {}'.format(pad_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Siamese network\n",
    "\n",
    "The following image is from [Learning a Similarity Metric Discriminatively, with Application to Face Verification](http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf) and it depicts a siamese network.\n",
    "\n",
    "<img src=\"figures/siamese-lecun.png\" alt=\"Siamese Network\" style=\"width: 800px;\"/>\n",
    "\n",
    "The key characteristics of such a network are:\n",
    "* the input is constituted by a pair of objects\n",
    "* each input is encoded independently by the same module (parameters are shared between branches)\n",
    "* an energy function computes the distance or similarity between the encoded representations\n",
    "* a contrastive loss is used to optimize the network\n",
    "\n",
    "## Contrastive loss\n",
    "\n",
    "We select the cosine loss between sentence embeddings as our contrastive loss.\n",
    "\n",
    "PyTorch already contains an implementation of such loss, called [CosineEmbeddingLoss](https://pytorch.org/docs/master/nn.html#torch.nn.CosineEmbeddingLoss):\n",
    "\n",
    "<img src=\"figures/cosine-loss.png\" alt=\"Cosine Embedding Loss\" style=\"width: 600px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dummy_vector_a = torch.autograd.Variable(torch.FloatTensor([[1., 2.]]))\n",
    "dummy_vector_b = torch.autograd.Variable(torch.FloatTensor([[1., 2.]]))\n",
    "\n",
    "dummy_label = torch.autograd.Variable(torch.FloatTensor([[-1]]))\n",
    "\n",
    "print(F.cosine_similarity(dummy_vector_a, dummy_vector_b))\n",
    "\n",
    "print(torch.nn.CosineEmbeddingLoss(margin=0.4)(dummy_vector_a, dummy_vector_b, dummy_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plotting the loss: y == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sims, losses = [], []\n",
    "for sim in [0.01 * x for x in range(-100, 101)]:\n",
    "    sims.append(sim)\n",
    "    losses.append(1 - sim)\n",
    "    \n",
    "loss_df = pd.DataFrame()\n",
    "loss_df[\"cosine similarity\"] = sims\n",
    "loss_df[\"loss\"] = losses\n",
    "loss_df.plot(x=\"cosine similarity\", y=\"loss\", figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plotting the loss: y == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "margin = 0.5\n",
    "sims, losses = [], []\n",
    "for sim in [0.01 * x for x in range(-100, 101)]:\n",
    "    sims.append(sim)\n",
    "    losses.append(max(0, sim - margin))\n",
    "    \n",
    "loss_df = pd.DataFrame()\n",
    "loss_df[\"cosine similarity\"] = sims\n",
    "loss_df[\"loss\"] = losses\n",
    "loss_df.plot(x=\"cosine similarity\", y=\"loss\", figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Siamese network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):  \n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 word_vocab_size,\n",
    "                 hidden_size,\n",
    "                 data):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.word_emb = nn.Embedding(word_vocab_size, embedding_dim)\n",
    "        self.word_emb.weight.data.copy_(data.TEXT.vocab.vectors)\n",
    "        self.word_emb.weight.requires_grad = False\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(kernel_size=1, in_channels=embedding_dim,\n",
    "                                out_channels=self.hidden_size)\n",
    "        self.conv_2 = nn.Conv1d(kernel_size=3, in_channels=embedding_dim,\n",
    "                                out_channels=self.hidden_size)\n",
    "        self.conv_3 = nn.Conv1d(kernel_size=5, in_channels=embedding_dim,\n",
    "                                out_channels=self.hidden_size)\n",
    "        self.convs = [self.conv_1, self.conv_2, self.conv_3]\n",
    "        \n",
    "        self.criterion = torch.nn.CosineEmbeddingLoss(margin=0.8)\n",
    "        \n",
    "    def encode(self, question):\n",
    "        emb = self.word_emb(question)\n",
    "        emb_for_conv = emb.transpose(1, 2)\n",
    "        \n",
    "        pooled_outputs = []\n",
    "        for conv_layer in self.convs:\n",
    "            conv = conv_layer(emb_for_conv)\n",
    "            pooled_output = F.relu(F.max_pool1d(conv, conv.size(2))).squeeze(2)\n",
    "            pooled_outputs.append(pooled_output)\n",
    "            \n",
    "        return torch.cat(tuple(pooled_outputs), dim=1)\n",
    "\n",
    "    def forward(self, q1, q2):\n",
    "        encoded_q1 = self.encode(q1)\n",
    "        encoded_q2 = self.encode(q2)\n",
    "        return encoded_q1, encoded_q2\n",
    "    \n",
    "    def compute_batch_stats(self, model_output, batch):\n",
    "        \"\"\"Returns output, batch loss and number of correct predictions.\"\"\"\n",
    "        encoded_q1, encoded_q2 = model_output\n",
    "        \n",
    "        # Labels are mapped from 0/1 to -1/1.\n",
    "        batch_loss = self.criterion(encoded_q1, encoded_q2, batch.label.float() * 2.0 - 1.0 )\n",
    "        \n",
    "        similarity = F.cosine_similarity(encoded_q1, encoded_q2)\n",
    "        predictions = similarity.clone()\n",
    "        predictions[similarity > 0.5] = 1\n",
    "        predictions[similarity <= 0.5] = 0\n",
    "        correct_predictions = (predictions.squeeze() == batch.label.float()).sum().float()\n",
    "        \n",
    "        return similarity, batch_loss, correct_predictions      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multilayer Perceptron (MLP) baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):  \n",
    "    def __init__(self,\n",
    "                 context_dim,\n",
    "                 hidden_dim,\n",
    "                 attn_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.context_proj = nn.Linear(context_dim, attn_size, bias=True)\n",
    "        self.hidden_proj = nn.Linear(hidden_dim, attn_size, bias=True)\n",
    "        self.attn = nn.Linear(attn_size, 1, bias=True)\n",
    "    \n",
    "    def forward(self,\n",
    "                context,  # batch x context_dim\n",
    "                embedded_sequence,  # batch x sequence_length x hidden_dim\n",
    "                mask=None,\n",
    "               ):\n",
    "        augmented_hidden_state = self.context_proj(context).unsqueeze(1) + self.hidden_proj(\n",
    "            embedded_sequence)\n",
    "        augmented_hidden_state = context.unsqueeze(1) + embedded_sequence\n",
    "        attn_scores = F.tanh(self.attn(augmented_hidden_state))\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores.data.masked_fill_(mask.squeeze().byte().data, -9999.9)\n",
    "            \n",
    "        attn_scores = F.softmax(attn_scores)\n",
    "        return embedded_sequence * attn_scores\n",
    "\n",
    "class MLP(nn.Module):  \n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 word_vocab_size,\n",
    "                 hidden_size,\n",
    "                 data,\n",
    "                 use_attention=False):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        self.word_emb = nn.Embedding(word_vocab_size, embedding_dim)\n",
    "        self.word_emb.weight.data.copy_(data.TEXT.vocab.vectors)\n",
    "        self.word_emb.weight.requires_grad = False\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(kernel_size=3, in_channels=embedding_dim,\n",
    "                                out_channels=self.hidden_size, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(kernel_size=3, in_channels=embedding_dim,\n",
    "                                out_channels=self.hidden_size, padding=1)\n",
    "        \n",
    "        self.attention = Attention(self.hidden_size, self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        self.h1 = nn.Linear(self.hidden_size + self.hidden_size, 200, bias=True)\n",
    "        self.out = nn.Linear(200, 1, bias=True)\n",
    "        \n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, q1, q2):\n",
    "        encoded_q1 = self.conv_1(self.word_emb(q1).transpose(1, 2))\n",
    "        encoded_q2 = self.conv_2(self.word_emb(q2).transpose(1, 2))\n",
    "          \n",
    "        pooled_q1 = F.relu(F.max_pool1d(encoded_q1, encoded_q1.size(2))).squeeze(2)\n",
    "        \n",
    "        if self.use_attention:       \n",
    "            mask = torch.eq(q1, 1)  # <pad> id is 1\n",
    "            attended_q2 = self.attention(pooled_q1, encoded_q2.transpose(2, 1), mask)\n",
    "            attended_q2 = attended_q2.transpose(2, 1)\n",
    "            pooled_q2 = F.relu(F.max_pool1d(attended_q2, attended_q2.size(2))).squeeze(2)\n",
    "        else:\n",
    "            pooled_q2 = F.relu(F.max_pool1d(encoded_q2, encoded_q2.size(2))).squeeze(2)\n",
    "        \n",
    "        concat = torch.cat((pooled_q1, pooled_q2), dim=1)\n",
    "        \n",
    "        return self.out(F.relu(self.h1(concat))\n",
    "    \n",
    "    def compute_batch_stats(self, model_output, batch):\n",
    "        \"\"\"Returns output, batch loss and number of correct predictions.\"\"\"\n",
    "        batch_loss = self.criterion(model_output, batch.label.float().view((-1, 1)))\n",
    "        \n",
    "        sigmoid_output = F.sigmoid(model_output)\n",
    "        predictions = sigmoid_output.clone()\n",
    "        predictions[sigmoid_output > 0.5] = 1\n",
    "        predictions[sigmoid_output <= 0.5] = 0\n",
    "        correct_predictions = (predictions.squeeze() == batch.label.float()).sum().float()\n",
    "        \n",
    "        return sigmoid_output, batch_loss, correct_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Network instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode = 'siamese'\n",
    "\n",
    "if mode == 'siamese':\n",
    "    network = SiameseNetwork(embedding_dim, word_vocab_size, hidden_size, dataset)\n",
    "else:\n",
    "    network = MLP(embedding_dim, word_vocab_size, hidden_size, dataset, use_attention=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    network = network.cuda()\n",
    "\n",
    "# Collect the parameters to update.\n",
    "parameters = filter(lambda p: p.requires_grad, network.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
    "\n",
    "network.train()\n",
    "best_model = copy.deepcopy(network)\n",
    "\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Testing procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(model, data, max_sent_len, mode='test'):\n",
    "    if mode == 'dev':\n",
    "        iterator = iter(data.dev_iter)\n",
    "    else:\n",
    "        iterator = iter(data.test_iter)\n",
    "    model.eval()\n",
    "    \n",
    "    correct_predictions, loss, number_of_samples = 0, 0, 0\n",
    "    for batch in iterator:\n",
    "        s1, s2 = 'q1', 'q2'\n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "        model_output = model(s1, s2)\n",
    "        \n",
    "        output, batch_loss, batch_correct_predictions = model.compute_batch_stats(model_output,\n",
    "                                                                                  batch)\n",
    "\n",
    "        correct_predictions += batch_correct_predictions\n",
    "        number_of_samples += len(output)\n",
    "        loss += batch_loss.data[0]\n",
    "\n",
    "    acc = correct_predictions / number_of_samples\n",
    "    acc = acc.cpu().data[0]\n",
    "    \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('[INFO] Starting training...')\n",
    "\n",
    "loss, last_epoch = 0, -1\n",
    "max_dev_acc, max_test_acc = 0, 0\n",
    "\n",
    "iterator = dataset.train_iter\n",
    "\n",
    "for i, batch in enumerate(iterator):\n",
    "    current_epoch = int(iterator.epoch)\n",
    "    if current_epoch == num_epochs:\n",
    "        break\n",
    "    if current_epoch > last_epoch:\n",
    "        print('[INFO] Epoch: {}'.format(current_epoch + 1))\n",
    "    last_epoch = current_epoch\n",
    "    \n",
    "    s1, s2 = 'q1', 'q2'\n",
    "    s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "\n",
    "    model_output = network(s1, s2)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, batch_loss, batch_correct_predictions = network.compute_batch_stats(model_output,\n",
    "                                                                                batch)\n",
    "    \n",
    "    loss += batch_loss.data[0]\n",
    "    batch_loss.backward()       \n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i + 1) % print_freq == 0:\n",
    "        dev_loss, dev_acc = test(network, dataset, max_sent_len, mode='dev')\n",
    "        test_loss, test_acc = test(network, dataset, max_sent_len)\n",
    "        c = (i + 1) // print_freq\n",
    "\n",
    "        print('[INFO] train loss: {:.2f} / dev loss: {:.2f} / test loss: {:.2f}'\n",
    "              ' / dev acc: {:.2f} / test acc: {:.2f}'.format(loss, dev_loss,\n",
    "                                                             test_loss,\n",
    "                                                             dev_acc * 100,\n",
    "                                                             test_acc * 100))\n",
    "\n",
    "        if dev_acc > max_dev_acc:\n",
    "            max_dev_acc = dev_acc\n",
    "            max_test_acc = test_acc\n",
    "            best_model = copy.deepcopy(network)\n",
    "\n",
    "        loss = 0\n",
    "        network.train()\n",
    "\n",
    "print('[INFO] max dev acc: {:.2f} / max test acc: {:.2f}'.format(max_dev_acc * 100,\n",
    "                                                                 max_test_acc * 100))\n",
    "\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')\n",
    "    \n",
    "torch.save(best_model.state_dict(), 'saved_models/network_quora.pt')\n",
    "\n",
    "print('[INFO] Training finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exploration of the cutting point for computing the accuracy\n",
    "\n",
    "As you can see from the accuracy above, the results seem a bit disappointing. The problem is that the threshold at which the similarities are binarized is 0.5, and the distance at which the network tries to put different examples is at least 0.8. Let's compute the accuracies varying the cutting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_on_dataset(dataset_iterator):\n",
    "    similarities = []\n",
    "    labels = []\n",
    "    for batch in dataset_iterator:\n",
    "        s1, s2 = 'q1', 'q2'\n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "\n",
    "        model_output = best_model(s1, s2)\n",
    "        encoded_q1, encoded_q2 = model_output\n",
    "\n",
    "        similarity = F.cosine_similarity(encoded_q1, encoded_q2)\n",
    "\n",
    "        similarities.extend(similarity)\n",
    "        labels.extend(batch.label)\n",
    "        \n",
    "    similarities = torch.cat(similarities)\n",
    "    labels = torch.cat(labels)\n",
    "    \n",
    "    return similarities, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compute predictions on dev and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dev_similarities, dev_labels = predict_on_dataset(iter(dataset.dev_iter))\n",
    "test_similarities, test_labels = predict_on_dataset(iter(dataset.test_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plot the accuracy at different cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels, cut):\n",
    "    preds = predictions.data.cpu().numpy().tolist()\n",
    "    lbs = labels.data.cpu().numpy().tolist()\n",
    "    correct_predictions = 0\n",
    "    number_of_predictions = 0\n",
    "    for pred, lb in zip(preds, lbs):\n",
    "        pred_lb = 1 if pred > cut else 0\n",
    "        if pred_lb == lb:\n",
    "            correct_predictions += 1\n",
    "        number_of_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / float(number_of_predictions)\n",
    "    return accuracy * 100\n",
    "\n",
    "def find_best_accuracy(similarities, labels):\n",
    "    cuts = []\n",
    "    accuracies = []\n",
    "    max_accuracy, max_cut = 0.0, 0.0\n",
    "    for cut in [0.01 * i for i in range(0, 101)]:\n",
    "        accuracy = compute_accuracy(similarities, labels, cut)\n",
    "        cuts.append(cut)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            max_cut = cut\n",
    "\n",
    "    cut_accuracy_df = pd.DataFrame()\n",
    "    cut_accuracy_df[\"cut\"] = cuts\n",
    "    cut_accuracy_df[\"accuracy\"] = accuracies\n",
    "    cut_accuracy_df.plot(x=\"cut\", y=\"accuracy\", figsize=(10,10))\n",
    "\n",
    "    return max_cut, max_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Find the best accuracy on the development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_dev_cut, best_dev_accuracy = find_best_accuracy(dev_similarities, dev_labels)\n",
    "print(\"[INFO] Best dev accuracy at cut {}: {}\".format(best_dev_cut, best_dev_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_test_cut, best_test_accuracy = find_best_accuracy(test_similarities, test_labels)\n",
    "print(\"[INFO] Best test accuracy at cut {}: {}\".format(best_test_cut, best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] Test accuracy at best dev cut: {}\".format(compute_accuracy(test_similarities,\n",
    "                                                                         test_labels, best_dev_cut)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loss on triplets\n",
    "\n",
    "Each training instance is composed by three item:\n",
    "\n",
    "1. A first item that we call target (e.g., target question)\n",
    "2. A second item which is related to the target item (e.g., question similar to the target question)\n",
    "3. A third item which is NOT related to the target item (e.g., question unrelated to the target question)\n",
    "\n",
    "Question: how do we create training instances?\n",
    "\n",
    "* Use available positive pairs and related negative items if present\n",
    "* Randomly sample a negative example (negative sampling)\n",
    "* Select a negative example according to a score (most similar negative example, most difficult negative example for the current network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Siamese triplet loss ([Wang et al. 2014](https://arxiv.org/abs/1404.4661))\n",
    "\n",
    "### $max\\{0, M - (cos(E(q), E(q^{+}))\\} - (cos(E(q), E(q^{-}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Twin loss\n",
    "\n",
    "### $max\\{0, M_{1} - (cos(E(q), E(q^{+}))\\} + max\\{0, (cos(E(q), E(q^-)) - M_{2}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ATTENTION MECHANISMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Computing the attention\n",
    "\n",
    "In this section we will apply the attention mechanism to compute a representation of second question which is conditioned on the first question, similar to the following paper: [Improved Representation Learning for Question Answer Matching](http://www.aclweb.org/anthology/P16-1044)\n",
    "\n",
    "<img src=\"figures/attentive-network.png\" alt=\"Attentive network\" style=\"width: 500px;\"/>\n",
    "\n",
    "In this figure, the question and answer are encoded with a recurrent network which outputs a hidden state for each token (we use wide convolutions to obtain hidden states). Then, the question hidden states are pooled to obtain a single vector. The latter is used in the attention network to compute a scalar value for each answer hidden state. This value is then used to rescale the corresponding hidden state. In equations:\n",
    "\n",
    "<img src=\"figures/attention.png\" alt=\"Attentive network\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):  \n",
    "    def __init__(self,\n",
    "                 context_dim,\n",
    "                 hidden_dim,\n",
    "                 attn_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.context_proj = nn.Linear(context_dim, attn_size, bias=True)\n",
    "        self.hidden_proj = nn.Linear(hidden_dim, attn_size, bias=True)\n",
    "        self.attn = nn.Linear(attn_size, 1, bias=True)\n",
    "    \n",
    "    def forward(self,\n",
    "                context,  # batch x context_dim\n",
    "                embedded_sequence,  # batch x sequence_length x hidden_dim\n",
    "                mask=None,\n",
    "               ):\n",
    "        augmented_hidden_state = self.context_proj(context).unsqueeze(1) + self.hidden_proj(\n",
    "            embedded_sequence)\n",
    "        augmented_hidden_state = context.unsqueeze(1) + embedded_sequence\n",
    "        attn_scores = F.tanh(self.attn(augmented_hidden_state))\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores.data.masked_fill_(mask.byte().data, -9999.9)\n",
    "            \n",
    "        attn_scores = F.softmax(attn_scores)\n",
    "\n",
    "        return embedded_sequence * attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Broadcasting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "emb_dim = 3\n",
    "seq_len = 2\n",
    "\n",
    "# First broadcasting example:\n",
    "# the batch_size x 1 vector is \"copied\" across the second dimension to match batch_size x emb_dim\n",
    "# This means that each value is \"copied\" emb_dim times -> [[1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]]\n",
    "sample_context = np.ones((batch_size, emb_dim)) * np.array([1, 2, 3, 4]).reshape(batch_size, 1)\n",
    "\n",
    "sample_embedded_sequence = np.ones((batch_size, seq_len, emb_dim))\n",
    "\n",
    "print(\"sample_context\")\n",
    "print(sample_context)\n",
    "print(\"\")\n",
    "print(\"sample_embedded_sequence (shape: {})\".format(sample_embedded_sequence.shape))\n",
    "print(sample_embedded_sequence)\n",
    "print(\"\")\n",
    "print(\"Context shape and context shape with additional singleton dim\")\n",
    "print(sample_context.shape)\n",
    "print(np.expand_dims(sample_context, axis=1).shape)\n",
    "print(\"\")\n",
    "# Second examples: the context values are \"copied\" across the singleton dimension to match seq_len\n",
    "print(\"Context added to each sequence hidden state\")\n",
    "print(np.expand_dims(sample_context, axis=1) + sample_embedded_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
